{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "checkpoint_path = '/workspace/models/fine-tuned/bert_tf_v2_base_fp16_128_v2/model.ckpt-8144'\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "names_nv = [key for key in var_to_shape_map]\n",
    "# for key in var_to_shape_map:\n",
    "#     print(\"tensor_name: \", key)\n",
    "#     print(reader.get_tensor(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'eval_ckpts/model.ckpt-315171'\n",
    "# 'output/model.ckpt-0'\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "names_sp = [key for key in var_to_shape_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'output/model.ckpt-0'\n",
    "# 'eval_ckpts/model.ckpt-315171'\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "names_op = [key for key in var_to_shape_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 618, 604)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_nv), len(names_sp), len(names_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# names_nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['fc0/weights/adam_m',\n",
       "  'fc0/biases/adam_m',\n",
       "  'conv2/kernel/adam_v',\n",
       "  'conv2/kernel/adam_m',\n",
       "  'conv2/biases/adam_v',\n",
       "  'conv2/biases/adam_m',\n",
       "  'conv1/kernel',\n",
       "  'conv1/biases',\n",
       "  'conv0/kernel/adam_v',\n",
       "  'conv0/kernel/adam_m',\n",
       "  'conv0/kernel',\n",
       "  'conv0/biases',\n",
       "  'conv2/kernel',\n",
       "  'conv1/kernel/adam_m',\n",
       "  'conv0/biases/adam_m',\n",
       "  'conv0/biases/adam_v',\n",
       "  'fc0/biases',\n",
       "  'conv1/biases/adam_v',\n",
       "  'conv2/biases',\n",
       "  'fc0/weights',\n",
       "  'fc0/biases/adam_v',\n",
       "  'fc0/weights/adam_v',\n",
       "  'conv1/biases/adam_m',\n",
       "  'conv1/kernel/adam_v'],\n",
       " ['output_weights/adam_v',\n",
       "  'output_weights/adam_m',\n",
       "  'output_bias/adam_v',\n",
       "  'output_bias',\n",
       "  'bert/pooler/dense/kernel/adam_m',\n",
       "  'output_weights',\n",
       "  'output_bias/adam_m',\n",
       "  'bert/pooler/dense/bias/adam_m',\n",
       "  'bert/pooler/dense/bias/adam_v',\n",
       "  'bert/pooler/dense/kernel/adam_v'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in names_sp if name not in names_op], [name for name in names_op if name not in names_nv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1/kernel',\n",
       " 'conv1/biases',\n",
       " 'conv0/kernel',\n",
       " 'conv0/biases',\n",
       " 'conv2/kernel',\n",
       " 'fc0/biases',\n",
       " 'conv2/biases',\n",
       " 'fc0/weights']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ons = [name for name in names_sp if name not in names_nv and 'adam' not in name]\n",
    "add_ons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cls/squad/output_weights/adam_m',\n",
       " 'cls/squad/output_bias/adam_v',\n",
       " 'cls/squad/output_bias/adam_m',\n",
       " 'cls/squad/output_bias',\n",
       " 'cls/squad/output_weights/adam_v',\n",
       " 'good_steps',\n",
       " 'cls/squad/output_weights',\n",
       " 'bad_steps',\n",
       " 'loss_scale']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in names_nv if name not in names_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import ctypes\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from tensorflow.python import pywrap_tensorflow as pyTF\n",
    "except ImportError as err:\n",
    "    sys.stderr.write(\"\"\"Error: Failed to import tensorflow module ({})\"\"\".format(err))\n",
    "    sys.exit()\n",
    "\n",
    "\"\"\"\n",
    "TensorRT Initialization\n",
    "\"\"\"\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "ctypes.CDLL(\"libnvinfer_plugin.so\", mode=ctypes.RTLD_GLOBAL)\n",
    "ctypes.CDLL(\"/workspace/TensorRT/demo/BERT/build/libcommon.so\", mode=ctypes.RTLD_GLOBAL)\n",
    "ctypes.CDLL(\"/workspace/TensorRT/demo/BERT/build/libbert_plugins.so\", mode=ctypes.RTLD_GLOBAL)\n",
    "\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, \"\")\n",
    "plg_registry = trt.get_plugin_registry()\n",
    "qkv2_plg_creator = plg_registry.get_plugin_creator(\"CustomQKVToContextPluginDynamic\", \"1\", \"\")\n",
    "skln_plg_creator = plg_registry.get_plugin_creator(\"CustomSkipLayerNormPluginDynamic\", \"1\", \"\")\n",
    "gelu_plg_creator = plg_registry.get_plugin_creator(\"CustomGeluPluginDynamic\", \"1\", \"\")\n",
    "emln_plg_creator = plg_registry.get_plugin_creator(\"CustomEmbLayerNormPluginDynamic\", \"1\", \"\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Attentions Keys\n",
    "\"\"\"\n",
    "WQ = \"query_kernel\"\n",
    "BQ = \"query_bias\"\n",
    "WK = \"key_kernel\"\n",
    "BK = \"key_bias\"\n",
    "WV = \"value_kernel\"\n",
    "BV = \"value_bias\"\n",
    "WQKV = \"qkv_kernel\"\n",
    "BQKV = \"qkv_bias\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Transformer Keys\n",
    "\"\"\"\n",
    "W_AOUT = \"attention_output_dense_kernel\"\n",
    "B_AOUT = \"attention_output_dense_bias\"\n",
    "AOUT_LN_BETA = \"attention_output_layernorm_beta\"\n",
    "AOUT_LN_GAMMA = \"attention_output_layernorm_gamma\"\n",
    "W_MID = \"intermediate_dense_kernel\"\n",
    "B_MID = \"intermediate_dense_bias\"\n",
    "W_LOUT = \"output_dense_kernel\"\n",
    "B_LOUT = \"output_dense_bias\"\n",
    "LOUT_LN_BETA = \"output_layernorm_beta\"\n",
    "LOUT_LN_GAMMA = \"output_layernorm_gamma\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Squad Output Keys\n",
    "\"\"\"\n",
    "SQD_W = \"squad_output_weights\"\n",
    "SQD_B = \"squad_output_bias\"\n",
    "\n",
    "\"\"\"\n",
    "CoLA Output Keys\n",
    "\"\"\"\n",
    "CoLA_W = \"output_weights\"\n",
    "CoLA_B = \"output_bias\"\n",
    "\n",
    "class BertConfig:\n",
    "    def __init__(self, bert_config_path):\n",
    "        with open(bert_config_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            self.num_attention_heads = data['num_attention_heads']\n",
    "            self.hidden_size = data['hidden_size']\n",
    "            self.intermediate_size = data['intermediate_size']\n",
    "            self.num_hidden_layers = data['num_hidden_layers']\n",
    "            self.use_fp16 = True\n",
    "\n",
    "\n",
    "def set_tensor_name(tensor, prefix, name):\n",
    "    tensor.name = prefix + name\n",
    "\n",
    "def set_layer_name(layer, prefix, name, out_idx = 0):\n",
    "    set_tensor_name(layer.get_output(out_idx), prefix, name)\n",
    "\n",
    "def attention_layer_opt(prefix, config, init_dict, network, input_tensor, imask):\n",
    "    \"\"\"\n",
    "    Add the attention layer\n",
    "    \"\"\"\n",
    "    assert(len(input_tensor.shape) == 5)\n",
    "    B, S, hidden_size, _, _ = input_tensor.shape\n",
    "    num_heads = config.num_attention_heads\n",
    "    head_size = int(hidden_size / num_heads)\n",
    "\n",
    "    Wall = init_dict[prefix + WQKV]\n",
    "    Ball = init_dict[prefix + BQKV]\n",
    "\n",
    "    mult_all = network.add_fully_connected(input_tensor, 3 * hidden_size, Wall, Ball)\n",
    "    set_layer_name(mult_all, prefix, \"qkv_mult\")\n",
    "\n",
    "    has_mask = imask is not None\n",
    "\n",
    "    pf_hidden_size = trt.PluginField(\"hidden_size\", np.array([hidden_size], np.int32), trt.PluginFieldType.INT32)\n",
    "    pf_num_heads = trt.PluginField(\"num_heads\", np.array([num_heads], np.int32), trt.PluginFieldType.INT32)\n",
    "    pf_has_mask = trt.PluginField(\"has_mask\", np.array([has_mask], np.int32), trt.PluginFieldType.INT32)\n",
    "\n",
    "    pfc = trt.PluginFieldCollection([pf_hidden_size, pf_num_heads, pf_has_mask])\n",
    "    qkv2ctx_plug = qkv2_plg_creator.create_plugin(\"qkv2ctx\", pfc)\n",
    "\n",
    "    qkv_in = [mult_all.get_output(0), imask]\n",
    "    qkv2ctx = network.add_plugin_v2(qkv_in, qkv2ctx_plug)\n",
    "    set_layer_name(qkv2ctx, prefix, \"context_layer\")\n",
    "    return qkv2ctx\n",
    "\n",
    "\n",
    "def skipln(prefix, init_dict, network, input_tensor, skip):\n",
    "    \"\"\"\n",
    "    Add the skip layer\n",
    "    \"\"\"\n",
    "    idims = input_tensor.shape\n",
    "    assert len(idims) == 5\n",
    "    hidden_size = idims[2]\n",
    "\n",
    "    pf_ld = trt.PluginField(\"ld\", np.array([hidden_size], np.int32), trt.PluginFieldType.INT32)\n",
    "    wbeta = init_dict[prefix + \"beta\"]\n",
    "    pf_beta = trt.PluginField(\"beta\", wbeta.numpy(), trt.PluginFieldType.FLOAT32)\n",
    "    wgamma = init_dict[prefix + \"gamma\"]\n",
    "    pf_gamma = trt.PluginField(\"gamma\", wgamma.numpy(), trt.PluginFieldType.FLOAT32)\n",
    "\n",
    "    pfc = trt.PluginFieldCollection([pf_ld, pf_beta, pf_gamma])\n",
    "    skipln_plug = skln_plg_creator.create_plugin(\"skipln\", pfc)\n",
    "\n",
    "    skipln_inputs = [input_tensor, skip]\n",
    "    layer = network.add_plugin_v2(skipln_inputs, skipln_plug)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def transformer_layer_opt(prefix, config, init_dict, network, input_tensor, imask):\n",
    "    \"\"\"\n",
    "    Add the transformer layer\n",
    "    \"\"\"\n",
    "    idims = input_tensor.shape\n",
    "    assert len(idims) == 5\n",
    "    hidden_size = idims[2]\n",
    "\n",
    "    context_transposed = attention_layer_opt(prefix + \"attention_self_\", config, init_dict, network, input_tensor, imask)\n",
    "    attention_heads = context_transposed.get_output(0)\n",
    "\n",
    "    W_aout = init_dict[prefix + W_AOUT]\n",
    "    B_aout = init_dict[prefix + B_AOUT]\n",
    "    attention_out_fc = network.add_fully_connected(attention_heads, hidden_size, W_aout, B_aout)\n",
    "\n",
    "    skiplayer = skipln(prefix + \"attention_output_layernorm_\", init_dict, network, attention_out_fc.get_output(0), input_tensor)\n",
    "    attention_ln = skiplayer.get_output(0)\n",
    "\n",
    "    W_mid = init_dict[prefix + W_MID]\n",
    "    B_mid = init_dict[prefix + B_MID]\n",
    "    mid_dense = network.add_fully_connected(attention_ln, config.intermediate_size, W_mid, B_mid)\n",
    "\n",
    "    mid_dense_out = mid_dense.get_output(0)\n",
    "\n",
    "    pfc = trt.PluginFieldCollection()\n",
    "    plug = gelu_plg_creator.create_plugin(\"gelu\", pfc)\n",
    "\n",
    "    gelu_layer = network.add_plugin_v2([mid_dense_out], plug)\n",
    "\n",
    "    intermediate_act = gelu_layer.get_output(0)\n",
    "    set_tensor_name(intermediate_act, prefix, \"gelu\")\n",
    "\n",
    "    # Dense to hidden size\n",
    "    W_lout = init_dict[prefix + W_LOUT]\n",
    "    B_lout = init_dict[prefix + B_LOUT]\n",
    "\n",
    "    out_dense = network.add_fully_connected(intermediate_act, hidden_size, W_lout, B_lout)\n",
    "    set_layer_name(out_dense, prefix + \"output_\", \"dense\")\n",
    "    out_layer = skipln(prefix + \"output_layernorm_\", init_dict, network, out_dense.get_output(0), attention_ln)\n",
    "    out_ln = out_layer.get_output(0)\n",
    "\n",
    "    set_tensor_name(out_ln, prefix + \"output_\", \"reshape\")\n",
    "\n",
    "    return out_ln\n",
    "\n",
    "\n",
    "def bert_model(config, init_dict, network, input_tensor, input_mask):\n",
    "    \"\"\"\n",
    "    Create the bert model\n",
    "    \"\"\"\n",
    "    prev_input = input_tensor\n",
    "    output = []\n",
    "    for layer in range(0, config.num_hidden_layers):\n",
    "        ss = \"l{}_\".format(layer)\n",
    "        prev_input = transformer_layer_opt(ss, config,  init_dict, network, prev_input, input_mask)\n",
    "        output.append(prev_input)\n",
    "    return prev_input, output\n",
    "\n",
    "\n",
    "def squad_output(prefix, config, init_dict, network, input_tensor):\n",
    "    \"\"\"\n",
    "    Create the squad output\n",
    "    \"\"\"\n",
    "\n",
    "    idims = input_tensor.shape\n",
    "    assert len(idims) == 5\n",
    "    B, S, hidden_size, _, _ = idims\n",
    "\n",
    "    W_out = init_dict[prefix + SQD_W]\n",
    "    B_out = init_dict[prefix + SQD_B]\n",
    "\n",
    "    W = network.add_constant((1, hidden_size, 2), W_out)\n",
    "    dense = network.add_fully_connected(input_tensor, 2, W_out, B_out)\n",
    "    set_layer_name(dense, prefix, \"dense\")\n",
    "    return dense\n",
    "\n",
    "\n",
    "def load_weights(inputbase):\n",
    "    \"\"\"\n",
    "    Load the weights from the tensorflow checkpoint\n",
    "    \"\"\"\n",
    "    weights_dict = dict()\n",
    "\n",
    "    try:\n",
    "        reader = pyTF.NewCheckpointReader(inputbase)\n",
    "        tensor_dict = reader.get_variable_to_shape_map()\n",
    "\n",
    "        # There might be training-related variables in the checkpoint that can be discarded\n",
    "        param_names = [key for key in sorted(tensor_dict) if 'adam' not in key and 'global_step' not in key and 'pooler' not in key]\n",
    "        count = len(param_names)\n",
    "        TRT_LOGGER.log(TRT_LOGGER.INFO, \"Found {:} entries in weight map\".format(count))\n",
    "\n",
    "        for pn in param_names:\n",
    "            toks = pn.lower().split('/')\n",
    "            if 'encoder' in pn:\n",
    "                assert ('layer' in pn)\n",
    "                l = (re.findall('\\d+', pn))[0]\n",
    "                outname = 'l{}_'.format(l) + '_'.join(toks[3:])\n",
    "            else:\n",
    "                outname = '_'.join(toks)\n",
    "\n",
    "            tensor = reader.get_tensor(pn)\n",
    "            shape = tensor.shape\n",
    "            if pn.find('kernel') != -1:\n",
    "                TRT_LOGGER.log(TRT_LOGGER.VERBOSE, \"Transposing {}\\n\".format(np))\n",
    "                tensor = np.transpose(tensor) # for kernel in conv layers, it's supposed to be\n",
    "                                              # transposed with(3,2,0,1), but since ours is 1d\n",
    "                                              # convolution, default (3,2,1,0) works fine.\n",
    "         \n",
    "            shape = tensor.shape\n",
    "            flat_tensor = tensor.flatten()\n",
    "            print(pn, shape, flat_tensor.shape)\n",
    "            shape_str = '{} '.format(len(shape)) + ' '.join([str(d) for d in shape])\n",
    "            weights_dict[outname] = trt.Weights(flat_tensor)\n",
    "\n",
    "            TRT_LOGGER.log(TRT_LOGGER.VERBOSE, \"Orig.name: {:}, TRT name: {:}, shape: {:}\".format(pn, outname, shape_str))\n",
    "\n",
    "        additional_dict = dict()\n",
    "        for key, value in weights_dict.items():\n",
    "            pos = key.find(BQ)\n",
    "            if pos != -1:\n",
    "                hidden_size = value.size\n",
    "                prefix = key[:pos]\n",
    "\n",
    "                Bq_ = value\n",
    "                Bk_ = weights_dict[prefix + BK]\n",
    "                Bv_ = weights_dict[prefix + BV]\n",
    "                Wq_ = weights_dict[prefix + WQ]\n",
    "                Wk_ = weights_dict[prefix + WK]\n",
    "                Wv_ = weights_dict[prefix + WV]\n",
    "\n",
    "                mat_size = hidden_size * hidden_size\n",
    "                wcount = 3 * mat_size\n",
    "                Wall = np.zeros(wcount, np.float32)\n",
    "                bcount = 3 * hidden_size\n",
    "                Ball = np.zeros(bcount, np.float32)\n",
    "                Wall[0:mat_size] = Wq_.numpy()[0:mat_size]\n",
    "                Wall[mat_size:2*mat_size] = Wk_.numpy()[0:mat_size]\n",
    "                Wall[2*mat_size:3*mat_size] = Wv_.numpy()[0:mat_size]\n",
    "                Ball[0:hidden_size] = Bq_.numpy()[0:hidden_size]\n",
    "                Ball[hidden_size:2*hidden_size] = Bk_.numpy()[0:hidden_size]\n",
    "                Ball[2*hidden_size:3*hidden_size] = Bv_.numpy()[0:hidden_size]\n",
    "\n",
    "                additional_dict[prefix + WQKV] = trt.Weights(Wall)\n",
    "                additional_dict[prefix + BQKV] = trt.Weights(Ball)\n",
    "\n",
    "    except Exception as error:\n",
    "        TRT_LOGGER.log(TRT_LOGGER.ERROR, str(error))\n",
    "\n",
    "    weights_dict.update(additional_dict)\n",
    "    return weights_dict\n",
    "\n",
    "\n",
    "def main(inputbase, B, S, bert_path, outputbase, task):\n",
    "    bert_config_path = os.path.join(bert_path, 'bert_config.json')\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, \"Using configuration file: {:}\".format(bert_config_path))\n",
    "    config = BertConfig(bert_config_path)\n",
    "\n",
    "    # Load weights from checkpoint file\n",
    "    init_dict = load_weights(inputbase)\n",
    "    \n",
    "    with trt.Builder(TRT_LOGGER) as builder:\n",
    "        ty = trt.PluginFieldType.FLOAT32\n",
    "\n",
    "        w = init_dict[\"bert_embeddings_layernorm_beta\"]\n",
    "        wbeta = trt.PluginField(\"bert_embeddings_layernorm_beta\", w.numpy(), ty)\n",
    "\n",
    "        w = init_dict[\"bert_embeddings_layernorm_gamma\"]\n",
    "        wgamma = trt.PluginField(\"bert_embeddings_layernorm_gamma\", w.numpy(), ty)\n",
    "\n",
    "        w = init_dict[\"bert_embeddings_word_embeddings\"]\n",
    "        wwordemb = trt.PluginField(\"bert_embeddings_word_embeddings\", w.numpy(), ty)\n",
    "\n",
    "        w = init_dict[\"bert_embeddings_token_type_embeddings\"]\n",
    "        wtokemb = trt.PluginField(\"bert_embeddings_token_type_embeddings\", w.numpy(), ty)\n",
    "\n",
    "        w = init_dict[\"bert_embeddings_position_embeddings\"]\n",
    "        wposemb = trt.PluginField(\"bert_embeddings_position_embeddings\", w.numpy(), ty)\n",
    "\n",
    "        pfc = trt.PluginFieldCollection([wbeta, wgamma, wwordemb, wtokemb, wposemb])\n",
    "        fn = emln_plg_creator.create_plugin(\"embeddings\", pfc)\n",
    "\n",
    "        explicit_batch_flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "        with builder.create_network(explicit_batch_flag) as network, builder.create_builder_config() as builder_config:\n",
    "            builder_config.max_workspace_size = 5000 * (1024 * 1024) # 5000 MiB\n",
    "            builder_config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "            input_ids = network.add_input(name=\"input_ids\", dtype=trt.int32, shape=(-1, S))\n",
    "            segment_ids = network.add_input(name=\"segment_ids\", dtype=trt.int32, shape=(-1, S))\n",
    "            input_mask = network.add_input(name=\"input_mask\", dtype=trt.int32, shape=(-1, S))\n",
    "\n",
    "            def set_profile_shape(profile, batch_size):\n",
    "                shape = (batch_size, S)\n",
    "                profile.set_shape(\"input_ids\", min=shape, opt=shape, max=shape)\n",
    "                profile.set_shape(\"segment_ids\", min=shape, opt=shape, max=shape)\n",
    "                profile.set_shape(\"input_mask\", min=shape, opt=shape, max=shape)\n",
    "\n",
    "            # Specify profiles for the batch sizes we're interested in.\n",
    "            # For maximum performance, we will tie each profile to exactly one shape rather than a range.\n",
    "            bs1_profile = builder.create_optimization_profile()\n",
    "            set_profile_shape(bs1_profile, 1)\n",
    "            builder_config.add_optimization_profile(bs1_profile)\n",
    "\n",
    "            bs_user_profile = builder.create_optimization_profile()\n",
    "            set_profile_shape(bs_user_profile, B)\n",
    "            builder_config.add_optimization_profile(bs_user_profile)\n",
    "\n",
    "            bs8_profile = builder.create_optimization_profile()\n",
    "            set_profile_shape(bs8_profile, 8)\n",
    "            builder_config.add_optimization_profile(bs8_profile)\n",
    "\n",
    "            # Create the network\n",
    "            inputs = [input_ids, segment_ids, input_mask]\n",
    "            emb_layer = network.add_plugin_v2(inputs, fn)\n",
    "\n",
    "            embeddings = emb_layer.get_output(0)\n",
    "            mask_idx = emb_layer.get_output(1)\n",
    "            if task == \"bert_embedding\":\n",
    "                bert_out, layers = bert_model(config, init_dict, network, embeddings, mask_idx)\n",
    "                B, S, hidden_size, _, _ = bert_out.shape\n",
    "                for i in range(len(layers)):\n",
    "                    print(i, layers[i].shape)\n",
    "                concat = network.add_concatenation(layers)\n",
    "                reshape = network.add_shuffle(concat.get_output(0))\n",
    "                reshape.reshape_dims = (B, S, len(layers), hidden_size)\n",
    "                reshape.second_transpose = (0, 2, 1, 3)\n",
    "                out = reshape.get_output(0)\n",
    "                \n",
    "            if task == \"squad\":\n",
    "                bert_out, _ = bert_model(config, init_dict, network, embeddings, mask_idx)\n",
    "                squad_logits = squad_output(\"cls_\", config, init_dict, network, bert_out)\n",
    "                out = squad_logits.get_output(0)\n",
    "            elif task == \"cola\":\n",
    "                bert_out, _ = bert_model(config, init_dict, network, embeddings, mask_idx)\n",
    "                cola_logits = cola_output('cola', config, init_dict, network, bert_out)\n",
    "                out = cola_logits.get_output(0)\n",
    "            print(out.shape)\n",
    "            network.mark_output(out)\n",
    "            print(\"Done building the network\")\n",
    "            with builder.build_engine(network, builder_config) as engine:\n",
    "                TRT_LOGGER.log(TRT_LOGGER.VERBOSE, \"Serializing Engine...\")\n",
    "                serialized_engine = engine.serialize()\n",
    "                TRT_LOGGER.log(TRT_LOGGER.INFO, \"Saving Engine to {:}\".format(outputbase))\n",
    "                with open(outputbase, 'wb') as fout:\n",
    "                    fout.write(serialized_engine)\n",
    "                TRT_LOGGER.log(TRT_LOGGER.INFO, \"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes: if conv layers are built using a for loop, conv_w & conv_b will be updated each iteration but its values will only be used during engine building process, so a bag is needed to hold them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cola_output(prefix, config, init_dict, network, input_tensor):\n",
    "    \"\"\"\n",
    "    Create the CoLA output\n",
    "    \"\"\"\n",
    "    idims = input_tensor.shape\n",
    "    assert len(idims) == 5\n",
    "    B, S, hidden_size, _, _ = idims\n",
    "  \n",
    "    # add shuffle layer for reshaping and permutation \n",
    "    shuffle = network.add_shuffle(input_tensor)\n",
    "    shuffle.first_transpose = (0, 2, 1, 3, 4)\n",
    "    shuffle.reshape_dims = (B, hidden_size, S,1)\n",
    "    input_tensor = shuffle.get_output(0)\n",
    "    print(input_tensor.shape)\n",
    "    # add convolution layers    \n",
    "    conv_outputs = []\n",
    "    bag = []\n",
    "    for i in range(3):\n",
    "        # add conv\n",
    "        kernel_size = trt.DimsHW(3 + i, 1)\n",
    "        conv_w = init_dict['conv{}_kernel'.format(i)]\n",
    "        conv_b = init_dict['conv{}_biases'.format(i)]\n",
    "        print(input_tensor.shape, kernel_size, conv_w.size)\n",
    "        conv = network.add_convolution(\n",
    "            input=input_tensor, \n",
    "            num_output_maps=100,\n",
    "            kernel_shape=kernel_size,\n",
    "            kernel=conv_w,\n",
    "            bias=conv_b\n",
    "        )\n",
    "        conv.stride = (1, 1)\n",
    "        conv.padding_mode=trt.PaddingMode.SAME_UPPER\n",
    "        bag += [conv_w, conv_b]\n",
    "        set_layer_name(conv, prefix, \"conv{}\".format(i))\n",
    "        print(\"conv output shape: \", conv.get_output(0).shape)\n",
    "        # add relu\n",
    "        relu = network.add_activation(input=conv.get_output(0), type=trt.ActivationType.RELU)\n",
    "        set_layer_name(relu, prefix, \"relu{}\".format(i))\n",
    "        # add pooling\n",
    "        pooling = network.add_pooling(\n",
    "            input=relu.get_output(0), \n",
    "            type=trt.PoolingType.MAX,\n",
    "            window_size=(8,1)\n",
    "        )\n",
    "        pooling.stride = (1, 1)\n",
    "        set_layer_name(pooling, prefix, \"pooling{}\".format(i))\n",
    "        print(\"Pooling output shape\", pooling.get_output(0).shape)\n",
    "        # for concat\n",
    "        conv_outputs.append(pooling.get_output(0))\n",
    "        \n",
    "    concat = network.add_concatenation(inputs=conv_outputs)\n",
    "    print(\"Concat output shape:\", concat.get_output(0).shape)\n",
    "    set_layer_name(concat, prefix, \"concat\")\n",
    "    # fc layer\n",
    "    dense = network.add_fully_connected(concat.get_output(0), 22, \n",
    "                                        init_dict['fc0_weights'].numpy(), init_dict['fc0_biases'].numpy())\n",
    "    set_layer_name(dense, prefix, \"dense\")\n",
    "    print(\"fc layer output shape: \", dense.get_output(0).shape)\n",
    "    \n",
    "    softmax = network.add_softmax(input=dense.get_output(0))\n",
    "    print(\"softmax layer output shape: \", softmax.get_output(0).shape)\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert/embeddings/LayerNorm/beta (768,) (768,)\n",
      "bert/embeddings/LayerNorm/gamma (768,) (768,)\n",
      "bert/embeddings/position_embeddings (512, 768) (393216,)\n",
      "bert/embeddings/token_type_embeddings (2, 768) (1536,)\n",
      "bert/embeddings/word_embeddings (30522, 768) (23440896,)\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_0/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_0/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_0/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_0/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_0/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_0/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_0/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_0/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_0/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_0/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_0/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_0/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_0/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_1/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_1/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_1/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_1/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_1/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_1/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_1/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_1/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_1/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_1/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_1/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_1/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_1/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_10/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_10/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_10/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_10/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_10/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_10/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_10/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_10/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_10/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_10/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_10/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_10/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_10/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_11/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_11/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_11/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_11/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_11/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_11/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_11/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_11/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_11/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_11/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_11/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_11/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_11/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_2/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_2/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_2/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_2/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_2/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_2/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_2/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_2/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_2/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_2/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_2/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_2/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_2/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_3/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_3/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_3/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_3/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_3/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_3/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_3/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_3/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_3/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_3/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_3/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_3/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_3/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_4/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_4/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_4/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_4/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_4/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_4/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_4/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_4/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_4/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_4/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_4/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_4/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_4/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_5/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_5/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_5/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_5/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_5/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_5/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_5/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_5/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_5/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_5/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_5/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_5/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_5/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_6/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_6/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_6/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_6/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_6/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_6/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_6/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_6/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_6/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_6/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_6/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_6/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_6/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_7/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_7/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_7/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_7/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_7/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_7/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_7/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_7/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_7/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_7/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_7/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_7/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_7/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_8/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_8/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_8/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_8/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_8/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_8/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_8/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_8/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_8/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_8/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_8/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_8/output/dense/bias (768,) (768,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert/encoder/layer_8/output/dense/kernel (768, 3072) (2359296,)\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_9/attention/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_9/attention/output/dense/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_9/attention/self/key/bias (768,) (768,)\n",
      "bert/encoder/layer_9/attention/self/key/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_9/attention/self/query/bias (768,) (768,)\n",
      "bert/encoder/layer_9/attention/self/query/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_9/attention/self/value/bias (768,) (768,)\n",
      "bert/encoder/layer_9/attention/self/value/kernel (768, 768) (589824,)\n",
      "bert/encoder/layer_9/intermediate/dense/bias (3072,) (3072,)\n",
      "bert/encoder/layer_9/intermediate/dense/kernel (3072, 768) (2359296,)\n",
      "bert/encoder/layer_9/output/LayerNorm/beta (768,) (768,)\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma (768,) (768,)\n",
      "bert/encoder/layer_9/output/dense/bias (768,) (768,)\n",
      "bert/encoder/layer_9/output/dense/kernel (768, 3072) (2359296,)\n",
      "conv0/biases (100,) (100,)\n",
      "conv0/kernel (100, 768, 3) (230400,)\n",
      "conv1/biases (100,) (100,)\n",
      "conv1/kernel (100, 768, 4) (307200,)\n",
      "conv2/biases (100,) (100,)\n",
      "conv2/kernel (100, 768, 5) (384000,)\n",
      "fc0/biases (22,) (22,)\n",
      "fc0/weights (300, 22) (6600,)\n",
      "0 (-1, 8, 768, 1, 1)\n",
      "1 (-1, 8, 768, 1, 1)\n",
      "2 (-1, 8, 768, 1, 1)\n",
      "3 (-1, 8, 768, 1, 1)\n",
      "4 (-1, 8, 768, 1, 1)\n",
      "5 (-1, 8, 768, 1, 1)\n",
      "6 (-1, 8, 768, 1, 1)\n",
      "7 (-1, 8, 768, 1, 1)\n",
      "8 (-1, 8, 768, 1, 1)\n",
      "9 (-1, 8, 768, 1, 1)\n",
      "10 (-1, 8, 768, 1, 1)\n",
      "11 (-1, 8, 768, 1, 1)\n",
      "(-1, 12, 8, 768)\n",
      "Done building the network\n"
     ]
    }
   ],
   "source": [
    "inputbase = 'eval_ckpts/model.ckpt-315171'# 'output/model.ckpt-0'\n",
    "outputbase = 'bert_embedding_8_batch1_single_profile.engine'\n",
    "B = 1\n",
    "S = 8\n",
    "bert_path = 'eval_ckpts'\n",
    "main(inputbase, B, S, bert_path, outputbase, 'bert_embedding')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
